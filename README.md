# Responsible AI Cases ğŸ•µï¸â€â™‚ï¸

This mini-project investigates two real-world scenarios where AI systems show signs of unfairness or ethical concerns.

## ğŸ‘‡ Included Cases

### 1. The Hiring Bot That Ghosted Women
- Scenario: AI screening system penalizes applicants with career gaps, disproportionately affecting women.
- Issue: Gender bias, lack of transparency.
- Fix: Train with diverse data and give feedback to rejected applicants.

### 2. The Proctoring AI That Cried "Cheater!"
- Scenario: AI flags students for cheating based on eye movement, disproportionately affecting neurodivergent students.
- Issue: Ableism, false positives.
- Fix: Use multimodal signals and always include human review.

## âœï¸ Author
Emmanuel Ouma â€” AI Ethics Explorer & Data Analyst  
